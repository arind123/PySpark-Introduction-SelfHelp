# -*- coding: utf-8 -*-
"""Pyspark_LinkedIn_Reported_Crimes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16NybOsad5LAIKOgBuqMvH1BXUcJgNhJM

**Install and start PySpark Session**
"""

!pip install pyspark

from pyspark.sql import SparkSession
from pyspark.sql.functions import to_timestamp, col, lit
spark = SparkSession.builder.appName('Practise_1').getOrCreate()

"""**Fiter data after transforming the Date columns into timestamps** """

rc_data = spark.read.csv('/content/drive/MyDrive/Colab Notebooks/PySpark/Reported_Crimes.csv', header = True).withColumn('Date',to_timestamp(col('Date'),'MM/dd/yyyy hh:mm:ss a')).withColumn('Updated On',to_timestamp(col('Updated On'),'MM/dd/yyyy hh:mm:ss a')).filter(col('Date') <= lit('2018-11-11'))
rc_data.show(5)

"""**Check the outcome**"""

rc_data.printSchema()

"""**Schemas**"""

## import specific modules for the Schemas
from pyspark.sql.types import StructType,StructField, StringType, IntegerType, TimestampType,BooleanType, DoubleType, IntegerType

## One way to do
StructType([
            StructField('ID',StringType,True),
            StructField('Case Number',StringType,True),
            StructField('Date',TimestampType,True),
            StructField('ID',StringType,True),
            StructField('ID',StringType,True),
            .....
            ......
])

##Another more simpler way

labels = [
  ('ID',StringType()),
  ('Case Number',StringType()),
  ('Date',TimestampType()),
  ('Block',StringType()),
  ('IUCR',StringType()),
  ('Primary Type',StringType()),
  ('Description',StringType()),
  ('Location Description',StringType()),
  ('Arrest',StringType()),
  ('Domestic',BooleanType()),
  ('Beat',StringType()),
  ('District',StringType()),
  ('Ward',StringType()),
  ('Community Area',StringType()),
  ('FBI Code',StringType()),
  ('X Coordinate',StringType()),
  ('Y Coordinate',StringType()),
  ('Year',StringType()),
  ('Updated On',TimestampType()),
  ('Latitude',DoubleType()),
  ('Longitude',DoubleType()),
  ('Location',StringType())
]

schema =  StructType([StructField(x[0],x[1],True) for x in labels])
print(schema)

rc_data = spark.read.csv('/content/drive/MyDrive/Colab Notebooks/PySpark/Reported_Crimes.csv', header = True,schema = schema).filter(col('Date') <= lit('2018-11-11'))
rc_data.printSchema()

"""**PySpark is very fussy about this data types**"""

rc_data.show() ### All of them become Null showing that some of the datatypes are not what we expected.

